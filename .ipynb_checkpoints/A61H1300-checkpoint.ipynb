{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A61H CPC Classification - A61H1300\n",
    "\n",
    "<font size=\"3\">\n",
    "\n",
    "#### About the Module:\n",
    "<I><span style=\"font-family:Arial\">This module work to identify patents in A61H1300 class. Class detail is as follow<br></span>\n",
    "<span style=\"font-family:Arial\">A61H13/00\t•\tGum massage<br></span>\n",
    "<span style=\"font-family:Arial\">A61H13/005\t•\tHydraulic gum massage<br></span>\n",
    "\n",
    "#### Input needed: \n",
    "<I><span style=\"font-family:Arial\">This module use libraries, function and processed text data present in initial_processing module</span></I>\n",
    "\n",
    "#### Output expected: \n",
    "<I><span style=\"font-family:Arial\">This module will identify patents in A61H1300 class in test data.<br>This output is pass to the module final_file. No output is expected in this module alone.</span></I>\n",
    "\n",
    "#### Related modules: \n",
    "<I><span style=\"font-family:Arial\">This module is calling initial_processing module and is called by final_file module</span></I>\n",
    "\n",
    "#### Who and when: \n",
    "<I><span style=\"font-family:Arial\">Last Modified by : Nishant Chauhan</span><br>\n",
    "<span style=\"font-family:Arial\">Last Modified on : 23-July-2020</span><br>\n",
    "<span style=\"font-family:Arial\">Version no       : 2</span><br>\n",
    "<span style=\"font-family:Arial\">Developed by     : Nishant Chauhan </span><br></font></I>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Initial_processing.ipynb\n",
      "Loading of module Initial processing is successfully complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import import_ipynb\n",
    "from Initial_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3849\n",
       "1      68\n",
       "Name: A61H1300, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A61H1300'] = df['CPC'].str.contains('A61H13|A61H0013|A61H 13').astype('int')\n",
    "df['A61H1300'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['A61H1300']\n",
    "\n",
    "model_title , score_title = train_model(X_title_dtm, y_train)\n",
    "\n",
    "y_pred_class_title = model_title.predict(X_title_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abstract , score_abstract = train_model(X_abstract_dtm, y_train)\n",
    "\n",
    "y_pred_class_abstract = model_abstract.predict(X_abstract_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy score :  0.9875774250507576\n"
     ]
    }
   ],
   "source": [
    "model_tab , score_tab = train_model(X_tab_dtm, y_train)\n",
    "\n",
    "y_pred_class_tab = model_tab.predict(X_tab_test_dtm)\n",
    "\n",
    "print(\"Training data accuracy score : \" ,((score_abstract.mean() + score_title.mean() + score_tab.mean())/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = pd.DataFrame(df_test[['number','title','abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first['title_prediction'] = y_pred_class_title\n",
    "df_first['abstract_prediction'] = y_pred_class_abstract\n",
    "df_first['all_text'] = X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting using words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND Operator keywords\n",
    "\n",
    "A61H1300 = ['hydraulic gum massage','teeth gum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEAR operator keywords (List1 NEAR5 List2)\n",
    "\n",
    "A61H1300_list1 = ['gum']\n",
    "A61H1300_list2 = ['massag', 'training', 'therap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSTO command e.g. search \"eye massage device\" as single word\n",
    "\n",
    "A61H1300_word = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = []\n",
    "for i in range(len(df_first['all_text'])):\n",
    "    check_word = (near_operator(df_first['all_text'][i],A61H1300_list1,A61H1300_list2, near=4) or \n",
    "                 and_operator(df_first['all_text'][i],A61H1300) or\n",
    "                 ssto(df_first['all_text'][i], A61H1300_word)) \n",
    "    new_col.append(check_word)\n",
    "    \n",
    "df_first['word_predict'] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first['A61H1300'] = df_first['word_predict'] + df_first['title_prediction'] + df_first['abstract_prediction']\n",
    "\n",
    "for row in range(len(df_first['A61H1300'])):\n",
    "    if df_first.loc[row, 'A61H1300'] > 0:\n",
    "        df_first.loc[row, 'A61H1300'] = 1\n",
    "    else:\n",
    "        df_first.loc[row, 'A61H1300'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second = df_first.drop(['title_prediction','abstract_prediction', 'word_predict'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-classification of A61H13/00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A61H13/005 • Hydraulic gum massage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND Operator keywords\n",
    "A61H13005 = ['hydraulic gum']\n",
    "\n",
    "# NEAR operator keywords (List1 NEAR5 List2)\n",
    "A61H13005_list1 = []\n",
    "A61H13005_list2 = []\n",
    "\n",
    "#SSTO command e.g. search \"eye massage device\" as single word\n",
    "A61H13005_word = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_13005 = []\n",
    "for i in range(len(df_second['all_text'])):\n",
    "    if df_second['A61H1300'][i] == 1:\n",
    "        check_word_13005 = int((near_operator(df_second['all_text'][i],A61H13005_list1,A61H13005_list2, near=4) or \n",
    "                           and_operator(df_second['all_text'][i],A61H13005) or\n",
    "                           ssto(df_second['all_text'][i], A61H13005_word)))\n",
    "    else:\n",
    "        check_word_13005 = 0\n",
    "    \n",
    "    new_col_13005.append(check_word_13005)\n",
    "    \n",
    "df_second['A61H13005'] = new_col_13005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4,len(df_second.columns)):\n",
    "    df_second.iloc[:,i].replace(1,df_second.columns[i], inplace=True)\n",
    "    df_second.iloc[:,i].replace(0,'', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['A61H1300', 'A61H13005']\n",
    "\n",
    "df_second['prediction'] = ''\n",
    "for i in range(len(df_second)):\n",
    "    for col in cols:\n",
    "        if not df_second.loc[i,col] == '':\n",
    "            df_second.loc[i,'prediction'] = (df_second.loc[i,'prediction'] + ' | '\n",
    "                                                        + df_second.loc[i,col])\n",
    "\n",
    "df_second['prediction'] = df_second['prediction'].str[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_second.drop(\n",
    "    columns= ['A61H1300', 'A61H13005', 'all_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of module A61H1300 is successfully complete.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt_string = datetime.now().strftime(\"%d/%b/%Y - %H:%M %p\")\n",
    "print(\"Module A61H1300 is successfully loaded on\",dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
