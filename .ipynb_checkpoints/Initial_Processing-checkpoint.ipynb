{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A61H CPC Classification\n",
    "\n",
    "<font size=\"3\">\n",
    "\n",
    "#### About the Module:\n",
    "<I><span style=\"font-family:Arial\">This module contains functions, libraries and initial processing of text data needed for CPC classification </span></I>\n",
    "\n",
    "#### Input needed: \n",
    "<I><span style=\"font-family:Arial\">This module use excel files extracted from Dervent Innovation for training and testing algorithms.<br> File named as \"Dataset for EPO Automation\" is use for training the models while excel file \"Testdata_EPO Automation\" contains patents whose classes we need to identify. <br> The excel files contains columns: <br> Publication number, inpadoc family, inpadoc family Id, title(english), title-dwpi, title-terms - dwpi, abstract-dwpi, abstract(english), abstract - dwpi use, abstract - dwpi advantage, abstract - dwpi drawing description, claims (english), description, cpc applied by clarivate, ipc Current Full, added by(self/client). </span></I>\n",
    "\n",
    "#### Output expected: \n",
    "<I><span style=\"font-family:Arial\">This module will provide functions and processed text data to other modules. No output is expected by executing this module alone.</span></I>\n",
    "\n",
    "#### Related modules: \n",
    "<I><span style=\"font-family:Arial\">This is the first module in the list and it is not calling any other module. However, this module is called by listed modules: <br> A61H0100, A61H0300, A61H0500, A61H0700, A61H0900, A61H1100, A61H1300, A61H1500, A61H1900, A61H2100, A61H2300, A61H3100, A61H3300, A61H3500, A61H3600, A61H3700, A61H3900 and final_file</span></I>\n",
    "\n",
    "#### Who and when: \n",
    "<I><span style=\"font-family:Arial\">Last Modified by : Nishant Chauhan</span><br>\n",
    "<span style=\"font-family:Arial\">Last Modified on : 20-July-2020</span><br>\n",
    "<span style=\"font-family:Arial\">Version no       : 2</span><br>\n",
    "<span style=\"font-family:Arial\">Developed by     : Nishant Chauhan </span><br></font></I>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_text(text_data):\n",
    "    \n",
    "    '''Process text data of the patent. Remove stop words, non-alphabetic text and lemmatize'''\n",
    "    \n",
    "    processed = text_data.str.lower()\n",
    "    processed = processed.apply(word_tokenize)    \n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x))\n",
    "    processed = processed.str.replace(r'[0-9-/]',' ')    \n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term.isalpha()))\n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x.split() if len(term) > 2))\n",
    "    \n",
    "    processed = processed.apply(lambda x: ' '.join(lemmatizer.lemmatize(term , wordnet.VERB) for term in x.split()))\n",
    "    processed = processed.apply(lambda x: ' '.join(lemmatizer.lemmatize(term , wordnet.NOUN) for term in x.split()))\n",
    "    processed = processed.apply(lambda x: ' '.join(lemmatizer.lemmatize(term , wordnet.ADJ) for term in x.split()))\n",
    "    processed = processed.apply(lambda x: ' '.join(lemmatizer.lemmatize(term , wordnet.ADV) for term in x.split()))\n",
    "    \n",
    "    #processed = processed.apply(lambda x: ' '.join(stemmer.stem(term) for term in x.split()))\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_text_no_lemma(text_data):\n",
    "    \n",
    "    '''Process text data of the patent.\n",
    "       Remove stop words, non-alphabetic text but no lemmatization. can be use if need to execute program quickly'''\n",
    "    \n",
    "    processed = text_data.str.lower()\n",
    "    processed = text_data.apply(word_tokenize)    \n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x))\n",
    "    processed = processed.str.replace(r'[0-9-]',' ')    \n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term.isalpha()))\n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "    processed = processed.apply(lambda x: ' '.join(term for term in x.split() if len(term) > 2))\n",
    "    \n",
    "    #processed = processed.apply(lambda x: ' '.join(stemmer.stem(term) for term in x.split()))\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(s, ch):\n",
    "    \n",
    "    '''To find the position of a word in text data. This function is used in near_operator function'''\n",
    "    \n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_operator(text, lista=[]):\n",
    "    \n",
    "    \"\"\"To check if words are present in the textual data. \n",
    "        This will work like 'AND' operator in Dervent Innovation.\"\"\"\n",
    "    \n",
    "    isin = False\n",
    "    for string in lista:\n",
    "        sub_isin = True\n",
    "        for substr in string.split(' '):\n",
    "            sub_isin = sub_isin & (substr in text)\n",
    "\n",
    "        isin = isin or sub_isin\n",
    "    return isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_operator(text,list1=[],list2=[],near=5):\n",
    "    \n",
    "    \"\"\"To check if words are present in the textual data. \n",
    "        This will work like 'NEAR' operator in Dervent Innovation. Default value of NEAR is 5\"\"\"\n",
    "    \n",
    "    isin, not_isin= 0,0\n",
    "    str_list = text.split(' ')        \n",
    "    for word in list1:\n",
    "        count_list = find(str_list,word)            \n",
    "\n",
    "        if (len(count_list) > 0):                \n",
    "            for word_count in count_list:  \n",
    "                sub_str = ' '.join(str_list[word_count-near:word_count+near+1])\n",
    "                    \n",
    "                for second_word in list2:\n",
    "                    if second_word in sub_str:\n",
    "                        isin = 1\n",
    "                    else:\n",
    "                        not_isin = 0        \n",
    "        \n",
    "    isin = isin or not_isin\n",
    "        \n",
    "    return isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssto(text,list1=[]):\n",
    "    \n",
    "    \"\"\"To check if multiple words are present in the textual data. \n",
    "        This will work like double inverted comma in Dervent Innovation.\"\"\"\n",
    "    \n",
    "    isin = 0\n",
    "    for word in list1:\n",
    "        if word in text:\n",
    "            isin = 1\n",
    "    \n",
    "    return isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_dtm, y_train):\n",
    "    \n",
    "    '''Train model using ensemble algorithms (Logistic Regression, Random Forest, Multinomial and SVM).'''\n",
    "    \n",
    "    clf1 = LogisticRegression(solver='liblinear',random_state=0)\n",
    "    clf2 = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "    clf3 = MultinomialNB()\n",
    "    clf4 = svm.SVC(kernel='linear', C=1, random_state=0, probability = True)\n",
    "    \n",
    "    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), ('svm',clf4)], voting='soft')\n",
    "    eclf = eclf.fit(X_train_dtm, y_train)\n",
    "    \n",
    "    scores = cross_val_score(eclf, X_train_dtm, y_train, cv=5)\n",
    "    \n",
    "    return eclf, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_values(eclf, y_test, X_test_dtm):\n",
    "    \n",
    "    '''This function will provide predicted class and its accuracy using ensemble algorithm'''\n",
    "    \n",
    "    y_pred_class = eclf.predict(X_test_dtm)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "    matrix_df = pd.DataFrame(matrix, columns = [['predicted', 'predicted'], ['Non-Relevant', 'Relevant']],\n",
    "                             index = [['actual', 'actual'], ['Non-Relevant', 'Relevant']])\n",
    "    \n",
    "    return accuracy,matrix_df, y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_scores(df, predicted, actual):\n",
    "    \n",
    "    ''' This function will generate accuracy score and confusion matrix'''\n",
    "    \n",
    "    nr00 = len(df[(df[predicted] == 0) & (df[actual] == 0)])\n",
    "    nr01 = len(df[(df[predicted] == 1) & (df[actual] == 0)])\n",
    "    nr10 = len(df[(df[predicted] == 0) & (df[actual] == 1)])\n",
    "    nr11 = len(df[(df[predicted] == 1) & (df[actual] == 1)])\n",
    "    \n",
    "    accuracy = (1- (nr01+nr10)/(nr00+nr01+nr10+nr11))*100\n",
    "    score = pd.DataFrame([(nr00,nr01),(nr10,nr11)],\n",
    "                        index = [['actual', 'actual'], ['Non-Relevant', 'Relevant']],\n",
    "                        columns = [['predicted', 'predicted'], ['Non-Relevant', 'Relevant']])\n",
    "    return score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_get_final_output(y_test, y_pred_class, X_test, df, cpc_class):\n",
    "    \n",
    "    '''This function will provide formatted dataframe of final predicted values of cpc classes'''\n",
    "    \n",
    "    combined_value = np.array([y_test, y_pred_class, X_test])\n",
    "    df_predicted = pd.DataFrame(combined_value.T, columns= ['Actual','Predicted', 'Text_Data'], index=X_test.index)   \n",
    "    select_text = df_predicted[(df_predicted['Predicted'] == 0) & (df_predicted['Actual'] == 1)]['Text_Data']\n",
    "    \n",
    "    for text in select_text.index:\n",
    "        check = is_in_text(select_text[text],cpc_class)\n",
    "        if check:\n",
    "            df_predicted['Predicted'][text] = 1\n",
    "    \n",
    "    intermediate_df = pd.concat([df, df_predicted], axis=1, join='inner')\n",
    "    \n",
    "    return intermediate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_scores(processed_df,CPCclass):\n",
    "    \n",
    "    ''' This function will generate final table, accuracy score and confusion matrix of final product'''\n",
    "    \n",
    "    nr00 = len(processed_df[(processed_df['Predicted'] == 0) & (processed_df['Actual'] == 0)])\n",
    "    nr01 = len(processed_df[(processed_df['Predicted'] == 1) & (processed_df['Actual'] == 0)])\n",
    "    nr10 = len(processed_df[(processed_df['Predicted'] == 0) & (processed_df['Actual'] == 1)])\n",
    "    nr11 = len(processed_df[(processed_df['Predicted'] == 1) & (processed_df['Actual'] == 1)])\n",
    "    accuracy = (1- (nr01+nr10)/(nr00+nr01+nr10+nr11))*100\n",
    "    \n",
    "    final_df = processed_df[['number', 'title', 'Predicted']].copy()\n",
    "    final_df = final_df.rename(columns={'Predicted' : CPCclass})\n",
    "    \n",
    "    score_df = pd.DataFrame([(nr00,nr01),(nr10,nr11)],\n",
    "                        index = [['actual', 'actual'], ['Non-Relevant', 'Relevant']],\n",
    "                        columns = [['predicted', 'predicted'], ['Non-Relevant', 'Relevant']])\n",
    "    \n",
    "    return final_df, score_df, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_excel(r'C:\\Users\\u6033331\\EPO dataset.xlsx')\n",
    "\n",
    "df_initial.fillna('na', inplace=True)\n",
    "\n",
    "df_initial['title'] = (df_initial['Title (English)'] + ' ' + \n",
    "                       df_initial['Title - DWPI'] + ' ' + \n",
    "                       df_initial['Title Terms - DWPI'])\n",
    "\n",
    "df_initial['abstract'] = (df_initial['Abstract - DWPI'] + ' ' + \n",
    "                          df_initial['Abstract (English)'] + ' ' + \n",
    "                          df_initial['Abstract - DWPI Use'] + ' ' + \n",
    "                          df_initial['Abstract - DWPI Advantage'] + ' ' + \n",
    "                          df_initial['Abstract - DWPI Drawing Description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Publication Number', \n",
    "        'title', \n",
    "        'abstract',\n",
    "        'INPADOC Family Members',\n",
    "        'INPADOC Family ID', \n",
    "        'Claims (English)', \n",
    "        'Description', \n",
    "        'CPC applied by clarivate', \n",
    "        'IPC Current Full', \n",
    "        'Added by'\n",
    "        ]\n",
    "\n",
    "df = df_initial[cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'INPADOC Family Members': 'family_member', \n",
    "                        'INPADOC Family ID': 'family_ID',\n",
    "                        'Claims (English)':'claim',\n",
    "                        'Description': 'desc', \n",
    "                        'CPC applied by clarivate': 'CPC',\n",
    "                        'IPC Current Full': 'IPC',\n",
    "                        'Publication Number': 'number'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_title = processed_text(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_abstract = processed_text(df['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_claim = processed_text(df['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_desc = processed_text(df['desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = processed_title\n",
    "df['abstract'] = processed_abstract\n",
    "df['claim'] = processed_claim\n",
    "df['desc'] = processed_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_initial = pd.read_excel(r'C:\\Users\\u6033331\\Testdata_EPO Automation.xlsx')\n",
    "\n",
    "df_test_initial.fillna('na', inplace=True)\n",
    "\n",
    "df_test_initial['title'] = (df_test_initial['Title (English)'] + ' ' + \n",
    "                       df_test_initial['Title - DWPI'] + ' ' + \n",
    "                       df_test_initial['Title Terms - DWPI'])\n",
    "\n",
    "df_test_initial['abstract'] = (df_test_initial['Abstract - DWPI'] + ' ' + \n",
    "                          df_test_initial['Abstract (English)'] + ' ' + \n",
    "                          df_test_initial['Abstract - DWPI Use'] + ' ' + \n",
    "                          df_test_initial['Abstract - DWPI Advantage'] + ' ' + \n",
    "                          df_test_initial['Abstract - DWPI Drawing Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_test = ['Publication Number', \n",
    "        'title', \n",
    "        'abstract',\n",
    "        'INPADOC Family Members',\n",
    "        'INPADOC Family ID', \n",
    "        'Claims (English)', \n",
    "        'Description']\n",
    "\n",
    "df_test = df_test_initial[cols_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.rename(columns={'INPADOC Family Members': 'family_member', \n",
    "                        'INPADOC Family ID': 'family_ID',\n",
    "                        'Claims (English)':'claim',\n",
    "                        'Description': 'desc', \n",
    "                        'Publication Number': 'number'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_title_test = processed_text(df_test['title'])\n",
    "processed_abstract_test = processed_text(df_test['abstract'])\n",
    "processed_claim_test = processed_text(df_test['claim'])\n",
    "processed_desc_test = processed_text(df_test['desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['title'] = processed_title_test\n",
    "df_test['abstract'] = processed_abstract_test\n",
    "df_test['claim'] = processed_claim_test\n",
    "df_test['desc'] = processed_desc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = df['title']\n",
    "X_abstract = df['abstract']\n",
    "\n",
    "X_test_title = df_test['title']\n",
    "X_test_abstract = df_test['abstract']\n",
    "\n",
    "X_tab = df_test['title'] + ' ' + df_test['abstract']\n",
    "X_ctb = df_test['title'] + ' ' + df_test['abstract'] + ' ' + df_test['claim']\n",
    "X_all = df_test['title'] + ' ' + df_test['abstract'] + ' ' + df_test['claim'] + ' ' + df_test['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_title = TfidfVectorizer(stop_words = 'english', max_features=2500)\n",
    "\n",
    "X_title_dtm = vect_title.fit_transform(X_title)\n",
    "X_title_test_dtm = vect_title.transform(X_test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vect_abstract = TfidfVectorizer(stop_words = 'english', max_features=2500)\n",
    "\n",
    "X_abstract_dtm = vect_abstract.fit_transform(X_abstract)\n",
    "X_abstract_test_dtm = vect_abstract.transform(X_test_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab_dtm = vect_title.transform(X_abstract)\n",
    "X_tab_test_dtm = vect_title.transform(X_test_abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Initial Processing is successfully loaded on 03/Aug/2020 - 15:15 PM\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt_string = datetime.now().strftime(\"%d/%b/%Y - %H:%M %p\")\n",
    "print(\"Module Initial Processing is successfully loaded on\",dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
